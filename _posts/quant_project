---
date: 2024-06-30 08:57:37
layout: post
title: "Portfolio Optimization"
subtitle: Brief overview of a personal project of mine
description: 
image: /assets/img/openai-whisper.jpg
optimized_image: /assets/img/openai-whisper.jpg
category: datascience
tags:
author:
paginate: 
---


> ##### Portfolio Management Simulation

This simulation demonstrates an investment strategy where a portfolio is managed actively to maintain a target allocation across various equities. It uses historical market data to simulate real-world trading conditions and adjusts the portfolio regularly to align with specified asset allocation goals. 

> ##### Key Components:
1. Asset Class:
 - Definition: Each asset in the portfolio, such as a stock, is characterized by its symbol, price, and type (e.g, equity or bond). 
 - Functionality: Assets can update their prices and calculate returns, providing dynamic interaction as market conditions change. 

2. Portfolio:
 - Initial Setup: Begins with a specified cash amount and a strategy for asset allocation. 
 - Operations: Includes capabilities to add or remove assets, calculate the total value, and rebalance the holdings to align with the target asset allocation. 

3. Rebalancing Strategy: 
 - Purpose: Ensures that the portfolio adheres to the desired asset distribution by adjusting the holdings periodically, based on the performance and fluctuations in asset values. 

4. Backtesting Environment:
 - Simulation: Runs the portfolio against historical data to demonstrate how it would perform over time, adjusting for price changes and rebalancing as needed. 
 - Metrics: Tracks and logs the portfolio's value over time, allowing for performance assessment and strategy refinement. 

> ##### Process Flow:
1. Initialization:
 - Assets are initialized with their respective symbols, initial prices, and types.
 - A portfolio is created with an initial cash balance and a defined target allocation for asset types. 

2. Simulation Execution:
 - The simulation iterates over a predefined range of business days, updating asset prices according to historical market data. 
 - On each simulated day, the portfolio is rebalanced to maintain the target allocation, adjusting asset quantities based on the latest prices and the available cash. 
 - The portfolio's total value is recalculated after adjustments to reflect the current market valuation of its holdings. 

3. Performance Tracking
 - The portfolio's value is recorded daily, providing a detailed view of its performance over the simulation period. 
 - The overall return is calculated at the end of the simulation to assess the effectiveness of the management strategy. 

> ##### Results Interpretation:
The simulation starts with an initial portfolio value of $10,000 and aims to maintain an allocation solely in equities as per the specified strategy. The portfolio includes a range of equities, each representing different sectors, ensuring diversification within the equity class. 

Over the simulated period of 256 business days starting at the beginning of the year 2023, the portfolio experiences fluctuations in value due to changes in the stock prices that are updated daily based on the historical market data. The portfolio management strategy involves rebalancing to maintain the target allocations, which incurs transaction costs but also helps in risk mitigation by maintaining a balanced asset distribution. 

At the end of the simulation:
 - Final Portfolio Value: The final recorded value of the portfolio after the last trading day stands at approximately $10,930.60
 - Total Return: The portfolio achieved a total return of 9.31% over the period. This return results from capital gains from the equities in the portfolio and the effectiveness of the rebalancing strategy in capitalizing on market movements. 


> ##### Background of Whisper AI model

This project utilizes the Whisper model from Open AI, which is an automatic speech recognition (ASR) system trained on 680,000 hours of multilingual and multitask supervised data collected from the web. The Whisper architecture is a simple end-to-end approach, implemented as an encoder-decoder Transformer. Input audio is split into 30-second chunks, converted into a log-Mel spectrogram, and then passed into an encoder. A decoder is trained to predict the corresponding text caption, intermixed with special tokens that direct the single model to perform tasks such as language identification, multilingual speech transcription, and to-English speech translation. 

![Whisper](/assets/img/whisper.jpg "Whisper")


> ##### Detailed Breakdown of the Audio Transcription Process

The application initiates by downloading audio from a specified YouTube URL, and saving it in MP3 format. This is followed by a conversion process where the downloaded MP3 file is transformed into WAV format, utilizing ffmpeg. This step is necessary as WAV files are uncompressed, meaning they contain raw audio data without any loss of quality. MP3 files, on the other hand, are compressed. The lossy nature of MP3 can lead to a reduction in the clarity and detail of the sound, which can affect the accuracy of speech recognition systems. Next, an essential step of resampling is incorporated. This step adjusts the sample rate of the audio data and interpolates it to align with the new sample rate, a crucial step to ensure compatibility with the Whisper AI model.

Finally, the transcribe audio function is activated. In this phase, the application loads the 'medium' model of Whisper AI and proceeds with the transcription of the audio into English. The outcome of this process is the return of the transcribed text. The entire workflow is seamlessly integrated and built using Streamlit. 

![gif](/assets/img/ips-82DEA1B7-D4EF-4E37-8B7E-C5CBF00A56B7.gif "gif")
 

> ##### Model Performance Comparison in Whisper AI

In my project, I compared Whisper AI's small, medium, and large models for audio transcription and translation on a 2-minute file. The small model, while it ran the fastest, performed badly in accuracy. Conversely, the large model excelled in accuracy with a near-perfect translation but it took about 4 minutes to run, which is double the audio's duration. I opted for the medium model, which provided a good balance of speed and accuracy, completing the task in about 20 seconds. Although its accuracy is slightly inferior to the large model, it still delivers a sufficiently accurate translation. 


> ##### Project Enhancements and Future Prospects

Given that the project currently operates on a CPU, a 2-minute duration was an ideal amount of time to test the performance. However, using a GPU could notably improve performance, especially by enabling the large Whisper AI model to process longer audio with greater transcription and translation accuracy. 


> ##### Future Development: Live Audio Translation Application

Moving forward with this project, I aim to develop a live audio translation application whereby real-time translation can be done as a video is playing on any platform. This application would be particularly useful for translating less commonly spoken languages and unique dialects that are only spoken within small communities. 


